## 🧠 **4-2. Agent 모델 **

---

### 1️⃣ **AI의 진화 단계**

| 구분                | 특징               | 예시                        |
| ----------------- | ---------------- | ------------------------- |
| **Perception AI** | 감지·분석 중심 (인식 기반) | Vision, Speech            |
| **Generative AI** | 콘텐츠 생성 중심        | GPT, Midjourney           |
| **Agentic AI**    | 능동적 행동 수행, 도구 사용 | ChatGPT Agent, Gemini CLI |
| **Physical AI**   | 현실 세계에서 물리적 작동   | 로봇, 자율주행                  |

💬 **핵심 변화:**
단순한 생성 → **“자율적 행동과 문제해결”** 로 발전
AI가 외부 도구를 호출하고, 계획을 세우며, 학습·협업까지 수행

---

### 2️⃣ **AI Agent의 정의와 핵심 특성**

* **정의:**
  사용자의 목표를 대신 달성하기 위해, 인식–추론–행동을 수행하는 자율형 소프트웨어 시스템

* **핵심 특성**

  | 요소                 | 설명                   |
  | ------------------ | -------------------- |
  | **자율성(Autonomy)**  | 인간 개입 없이 판단·실행       |
  | **인식(Perception)** | 외부 환경 데이터를 감지        |
  | **기억(Memory)**     | 과거 상태를 저장·활용         |
  | **추론(Reasoning)**  | 계획 수립 및 단계적 사고       |
  | **학습(Learning)**   | 피드백 기반 자기개선          |
  | **도구사용(Tool Use)** | 외부 시스템/API 호출로 작업 완수 |

---

### 3️⃣ **AI Agent의 도전 과제**

| 구분         | 내용                            |
| ---------- | ----------------------------- |
| **연구적 한계** | 협업 시스템 설계, 기억/컨텍스트 관리, 확장성 문제 |
| **실무적 한계** | 보안·프라이버시, 윤리적 편향, 실시간 비용 증가   |

---

## 🧩 **2. Multi-Agent System (MAS)**

### 🔹 개념

> 여러 개의 AI 에이전트가 협력·경쟁하며 **집단지성(Collective Intelligence)** 을 발휘하는 구조

* 인간 사회의 팀워크 원리와 유사
* 개별 에이전트의 한계를 극복

---

### 🔹 구성 요소

| 구성요소             | 설명                  |
| ---------------- | ------------------- |
| **Agent**        | 역할·능력·지식이 다른 개체     |
| **Environment**  | 상호작용이 일어나는 공간       |
| **Interaction**  | 메시지 기반 통신 (표준화된 언어) |
| **Organization** | 중앙집중형 / 탈중앙형 구조     |

---

### 🔹 협업 유형

| 유형                       | 설명              | 예시        |
| ------------------------ | --------------- | --------- |
| **협력(Cooperation)**      | 공동 목표 달성        | 논문 작성 시스템 |
| **경쟁(Competition)**      | 각자 목표 추구, 성능 경쟁 | 법정 시뮬레이션  |
| **협력적 경쟁(Co-opetition)** | 일부 협력 + 일부 경쟁   | 정책 결정 시스템 |

💡 **Mixture-of-Experts (MoE)**

* 여러 전문 모델이 서로 경쟁·협업하여 입력에 따라 최적의 전문가를 선택하는 구조

---

### 🔹 협력 전략(Methodology)

| 전략                    | 특징                     |
| --------------------- | ---------------------- |
| **규칙 기반(Protocol)**   | 사전 정의된 규칙에 따라 상호 비판·수정 |
| **역할 기반(Role-based)** | 각 에이전트에 역할 부여 (전문가 협업) |

---

### 🔹 커뮤니케이션 구조

| 구조        | 설명                | 장단점           |
| --------- | ----------------- | ------------- |
| **중앙집중형** | 중앙 에이전트가 소통·조율 담당 | 구현 쉬움, 확장성 낮음 |
| **탈중앙형**  | 각 에이전트가 직접 통신     | 확장성 높음, 설계 복잡 |

---

## 🧠 **3. Memory & Tool in Multi-Agent**

### 🔹 LLM → Agent로의 패러다임 전환

* LLM은 “고정된 매개변수 메모리”만 보유
* 에이전트는 **외부 도구와 실시간 정보** 활용

---

### 🔹 메모리 한계와 보완

| 한계                | 설명                |
| ----------------- | ----------------- |
| 낡은 지식             | 학습 시점 이후 정보 반영 불가 |
| 환각(Hallucination) | 비근거 정보 생성         |
| 사적 정보 미활용         | 개인·사내 데이터 접근 불가   |

💡 해결책: **RAG (검색증강생성)**
→ 신뢰할 수 있는 외부 지식 검색 후 응답 생성

---

### 🔹 기존 RAG의 한계

* 한 번만 검색 (일회성)
* 단일 소스 의존
* 맥락 저장 불가
  → “기억이 없는 검색 엔진”

---

### 🔹 **Agent형 RAG**

> LLM + 도구제어 → “스스로 검색, 평가, 재검색하는 RAG”

**기능:**
검색 여부 판단, 도구 선택, 쿼리 생성, 결과 평가

**구성 요소:**
LLM / 메모리 / 계획(Planning) / 도구(Tool)

---

## ⚙️ **4. 주요 Agent 기술 사례**

| 모델             | 핵심 아이디어                | 특징                |
| -------------- | ---------------------- | ----------------- |
| **Toolformer** | 자기지도학습으로 도구 사용법 스스로 학습 | API 호출 시점 스스로 결정  |
| **Gorilla**    | LLM + 실제 API 연결        | APIBench 데이터셋 기반  |
| **ReTool**     | 강화학습으로 도구 사용 타이밍 학습    | PPO + 결과 기반 보상    |
| **Search-R1**  | 강화학습 기반 웹검색 전략 최적화     | GRPO 기법 (PPO 개선형) |

---

## 🔗 **5. MCP (Model Context Protocol)**

> LLM–도구 간 표준 통신 프로토콜
> “AI 기능의 USB-C” 역할

| 구성요소       | 설명                       |
| ---------- | ------------------------ |
| **Host**   | AI 앱 환경 (예: IDE, Chat 앱) |
| **Client** | 통신 중개자                   |
| **Server** | 도구·리소스·프롬프트 제공           |

**핵심 기능**

* Tool: 실행 작업 (쿼리, 검색 등)
* Resource: 읽기 전용 데이터 (문서, DB)
* Prompt: 행동 지침 템플릿

💡 효과:

* 복잡한 연결(M×N) → 단순화(M+N)
* 재활용성·확장성 ↑

---

### 🧩 **A2A (Agent-to-Agent) Protocol**

* 여러 에이전트가 메모리·도구를 공유하지 않고,
  **지시·맥락·결과만 주고받는 협업 규격**
* MCP가 “도구 연결”이라면,
  A2A는 “에이전트 간 협업”

---

## 🔍 **6. Reasoning & Planning in AI Agent**

### 🔹 LLM의 추론 유도

* **Chain-of-Thought (CoT)**: 단계별 사고
* **자기일관성(Self-Consistency)**: 여러 reasoning 중 일관된 답 선택

### 🔹 Planning(계획) 강화 기법

| 방식               | 설명                           |
| ---------------- | ---------------------------- |
| **ReAct**        | 생각과 행동을 교차 반복 (reason + act) |
| **HuggingGPT**   | LLM이 하위 모델에 작업 분배            |
| **Reflection**   | 결과에 대한 자기 피드백                |
| **Plan-and-Act** | 계획 담당 + 실행 담당 에이전트 분리        |

---

### 🔹 최신 추론 모델

| 모델                          | 특징                  |
| --------------------------- | ------------------- |
| **o1 (OpenAI)**             | 강화된 reasoning 전용 모델 |
| **DeepSeek-R1**             | RLVR 기반 추론 모델       |
| **Gemini (Thought)**        | 멀티스텝 사고 지원          |
| **Claude (Thinking Block)** | 문장 단위 사고 구조         |
| **GPT (Reasoning Summary)** | 논리 기반 응답 최적화        |

---

### 🔹 효율적 추론 관리

| 접근                     | 내용              |
| ---------------------- | --------------- |
| **모델 기반 (DeGRPO)**     | 제어토큰으로 추론 길이 제어 |
| **결과 기반 (InftyThink)** | 중간 요약으로 동적 추론   |
| **입력 기반 (라우팅)**        | 질문 난이도별 연산량 조정  |

---

## 🧠 **7. 요약**

| 구분                 | 키포인트                      |
| ------------------ | ------------------------- |
| AI Agent 정의        | 자율적 사고·행동을 수행하는 AI        |
| MAS                | 협력·경쟁 기반 집단지성 시스템         |
| Agent형 RAG         | 검색·평가·재검색 가능한 RAG         |
| Toolformer 등       | 도구 사용을 학습하는 모델            |
| MCP                | 모델–도구 연결 표준               |
| A2A                | 에이전트 간 협업 표준              |
| ReAct / Reflection | 추론 + 행동 통합 전략             |
| Reasoning Model    | DeepSeek, o1, Gemini 등 발전 |

---
