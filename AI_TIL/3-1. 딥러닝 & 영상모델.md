## 🎥 **3-1. 딥러닝 & 영상모델**

### 1️⃣ **CNN (Convolutional Neural Network)**

#### 🔹 FCN vs CNN

| 구분     | FCN (Fully Connected Network) | CNN                   |
| ------ | ----------------------------- | --------------------- |
| 구조     | 입력을 1차원 벡터로 변환                | 입력의 2D 구조(공간정보) 유지    |
| 파라미터 수 | 매우 많음                         | 필터 가중치 공유로 효율적        |
| 특성     | 전체 이미지 통합 처리                  | 지역적 특징(엣지·색상 등) 추출 가능 |

#### 🔹 합성곱 연산 (Convolution)

* **필터(Filter)**: 이미지 위를 슬라이딩하며 내적 수행
* **출력**: Feature Map (특징맵)
* **패딩(Padding)**: 출력 크기 유지
* **스트라이드(Stride)**: 필터 이동 간격

#### 🔹 CNN 구조 요소

| 요소                        | 기능                         |
| ------------------------- | -------------------------- |
| **Convolution Layer**     | 이미지의 지역적 특징 추출             |
| **Pooling Layer**         | 해상도 축소 → 연산 효율 ↑, 위치 강건성 ↑ |
| **ReLU**                  | 비선형성 부여                    |
| **Fully Connected Layer** | 분류 결과 출력                   |

#### 🔹 수용 영역 (Receptive Field)

* CNN이 한 번에 “볼 수 있는” 입력 영역의 크기
* 레이어가 깊어질수록 넓어짐 → 더 큰 문맥 이해 가능

#### 🔹 풀링 (Pooling)

* **Max Pooling**: 각 영역의 최대값 선택
* **Average Pooling**: 평균값 사용
* 위치 변화에 강건, 연산량 절감
* **Stride Convolution**으로 대체 가능 (학습 가능한 축소 방식)

---

### 2️⃣ **CNN 기반 주요 모델 변천사**

#### 📘 ① **AlexNet (2012, ImageNet 우승)**

* **8층 구조 (5 Conv + 3 FC)**
* **ReLU** 활성화 함수 최초 도입
* GPU 병렬 학습 활용
* Dropout으로 과적합 방지
* 이미지 분류 정확도 대폭 향상

#### 📗 ② **VGGNet (2014)**

* **3×3 필터 반복**, 깊이로 성능 향상
* “작은 필터를 깊게 쌓으면 성능이 올라간다”
* 단순·규칙적인 설계 → 전이학습(Baseline)으로 인기
* 단점: 파라미터 많고 연산량 큼

#### 📙 ③ **ResNet (2015, Microsoft)**

* **Residual Block (잔차 연결)** 도입
  → `Output = F(x) + x`
  → 기울기 소실 방지, 깊은 네트워크 학습 가능
* **Batch Normalization / He 초기화** 사용
* **ResNet-50**: 가장 널리 쓰이는 CNN 백본

#### 📘 ④ **MobileNet (2017, Google)**

* **Depthwise Separable Convolution (깊이별 합성곱)**

  * 채널별로 분리된 3×3 합성곱 + 1×1 합성곱
* 연산량 약 **9배 절감**, 모델 경량화
* 모바일·엣지 디바이스용 모델의 표준 제시

---

### 3️⃣ **CNN의 한계**

| 한계               | 설명                    |
| ---------------- | --------------------- |
| **순서 무시**        | 시퀀스 데이터(문장, 음성) 처리 불가 |
| **장거리 의존성 부족**   | 멀리 떨어진 패턴 간 관계 파악 어려움 |
| **픽셀 단위 예측 어려움** | 생성·분할과 같은 정밀 작업 한계    |

---

### 4️⃣ **시퀀스 데이터 처리: RNN & LSTM**

#### 🔹 RNN (Recurrent Neural Network)

* 시계열 데이터 처리 구조
* **공식:** `h_t = f(W·h_{t-1} + U·x_t)`
* **특징:**

  * 순서 정보 반영
  * 동일한 가중치 반복 사용
* **한계:** 기울기 소실/폭발 문제

#### 🔹 LSTM (Long Short-Term Memory)

* RNN의 장기 의존성 문제 해결
* **게이트 구조**

  * Forget Gate: 이전 정보 제거
  * Input Gate: 새 정보 저장
  * Output Gate: 출력 제어
* **Cell State**로 정보 흐름 유지
* 단점: 정보 희석 가능

---

### 5️⃣ **Attention & ViT (Vision Transformer)**

#### 🔹 Attention의 핵심 구성

| 요소            | 역할         |
| ------------- | ---------- |
| **Query (Q)** | 어떤 정보를 찾을지 |
| **Key (K)**   | 각 입력의 특성   |
| **Value (V)** | 실제 정보 내용   |

> Attention(Q, K, V) = 유사도(Q, K) 기반으로 V를 가중합

* **Self-Attention**: 동일 입력 내 토큰 간 유사도 학습
* **Cross-Attention**: 서로 다른 입력(예: 텍스트↔이미지) 간 상호 연관성 학습

---

### 6️⃣ **ViT (Vision Transformer, 2020 Google)**

* 이미지 → **패치 단위 토큰화**
* 각 패치에 **위치 인코딩(Positional Encoding)** 추가
* 입력을 Transformer Encoder로 처리 → 전역 문맥 학습

#### 🔹 위치 인코딩 방식

| 유형                   | 특징                |
| -------------------- | ----------------- |
| **학습형(learnable)**   | 데이터 특화, 재학습 필요    |
| **사인파형(sinusoidal)** | 규칙 기반, 해상도 변화에 강함 |
| **상대 위치(relative)**  | 위치 간 거리 정보 반영     |

#### 🔹 ViT의 장단점

| 장점          | 단점                 |
| ----------- | ------------------ |
| 전역 문맥 고려    | 대규모 데이터 필요         |
| 순서 정보 반영 가능 | 학습 자원·메모리 요구 큼     |
| 전이학습 성능 우수  | 작은 데이터셋에선 CNN보다 약함 |

#### 🔹 ViT 응용 및 발전

* **Swin Transformer**: 윈도우 단위 지역 Attention → 효율성 개선
* **DINOv2 (Meta)**: 10억 파라미터, 자기지도학습
* **EVA-CLIP**: 이미지+텍스트 대조 학습
* **InternImage-H**: Conv+Transformer 하이브리드

---

### 7️⃣ **CNN vs ViT 요약비교**

| 구분 | CNN                 | ViT                   |
| -- | ------------------- | --------------------- |
| 구조 | 지역 합성곱 기반           | Self-Attention 기반     |
| 장점 | 연산 효율적, 소량 데이터에도 강함 | 전역 문맥 학습, 대규모 데이터에 강함 |
| 한계 | 장거리 관계 약함           | 학습 비용 큼               |
| 활용 | 분류·탐지               | 분류·분할·멀티모달            |

---

## 📚 핵심 포인트 정리

1. CNN은 **지역적 특징 학습**에 강점
2. ResNet은 **기울기 소실 해결의 혁신 모델**
3. MobileNet은 **경량화 CNN의 대표 모델**
4. Attention은 **긴 거리 관계 학습의 핵심 메커니즘**
5. ViT는 **Transformer를 영상에 적용**한 첫 사례로, 멀티모달 AI의 기반이 됨
